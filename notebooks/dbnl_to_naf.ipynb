{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e96133-8142-4640-b6bc-a67087419cdd",
   "metadata": {},
   "source": [
    "This notebook provides code that takes a folder of plays represented in dbnl as input and creates a folder of naf files that provide the spoken text of these plays as output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c771a38-ce49-4d34-b0c5-85617f91d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import lxml.etree as etree\n",
    "from KafNafParserPy import *\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc65446-921b-4c10-a1ff-ab3a2df86ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(xmlfile):\n",
    "    '''\n",
    "    Extracts the spoken text from a dbnl xml file representing a play\n",
    "    :param xmlfile: xmlinput file\n",
    "    :return: ordered dictionary with keys string n_speaker values spoken text\n",
    "    '''\n",
    "\n",
    "    my_xml = etree.parse(xmlfile)\n",
    "    speech_elements = my_xml.xpath('//sp')\n",
    "    counter = 0\n",
    "    speaker_text = OrderedDict()\n",
    "    \n",
    "    for speech in speech_elements:\n",
    "        counter += 1\n",
    "        text = ''\n",
    "        speaker = 'Unknown'\n",
    "        for child in speech:\n",
    "            if child.tag == 'speaker':\n",
    "                if len(child) > 0:\n",
    "                    speaker = child[0].text\n",
    "                    if speaker is None:\n",
    "                        speaker = 'Unknown'\n",
    "                elif child.text is None:\n",
    "                    speaker = 'Unknown'\n",
    "                else:\n",
    "                    speaker = child.text\n",
    "            elif child.tag == 'l':\n",
    "                #this file has a subelement with <hi> where the text is embedded. if child.text is None, check for child of child\n",
    "                if child.text is not None:\n",
    "                    text = text + \" \" + child.text\n",
    "                else:\n",
    "                    for gchild in child:\n",
    "                        if gchild.tag == 'hi':\n",
    "                            if gchild.text is None:\n",
    "                                if len(gchild) > 0:\n",
    "                                    text = text + \" \" + gchild[0].text\n",
    "                            else:\n",
    "                                text = text + \" \" + gchild.text\n",
    "        speaker_text[str(counter) + \"_\" + speaker] = text.lstrip(\" \")\n",
    "\n",
    "    return speaker_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2502b5-103a-4990-b51a-402fdf56d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def turn_text_to_tokens(speaker_text):\n",
    "    '''\n",
    "    This function will tokenize the text and return tokens and sentences,\n",
    "\n",
    "    :param speaker_text: ordered dictionary with keys string n_speaker values spoken text\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    speaker_tokens = OrderedDict()\n",
    "\n",
    "    for k, v in speaker_text.items():\n",
    "        tokens = word_tokenize(v)\n",
    "        speaker_tokens[k] = tokens\n",
    "\n",
    "    return speaker_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74379aac-ed02-4c15-8cc4-857529af709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_naf_file(text_dict, token_dict, outputfile):\n",
    "    '''\n",
    "    This function will create a naf file with a token layer\n",
    "    :param tokens:\n",
    "    :return:\n",
    "    '''\n",
    "    Nafparser = KafNafParser(type = 'NAF')\n",
    "    Nafparser.set_language('en')\n",
    "\n",
    "    my_lp = Nafparser.create_linguistic_processor('text', 'nltk', nltk.__version__)\n",
    "    Nafparser.add_linguistic_processor('text', my_lp)\n",
    "\n",
    "    index = 0\n",
    "    counter = 0\n",
    "    sent = 1\n",
    "\n",
    "    for k, v in token_dict.items():\n",
    "        span = []\n",
    "        prev_text = index\n",
    "        text = text_dict.get(k)\n",
    "        if text is None:\n",
    "            print('ERROR: orginal text not found for:', k)\n",
    "        else:\n",
    "            for token in v:\n",
    "                counter += 1\n",
    "                text_loc = index - prev_text\n",
    "                if text[text_loc] == token[0]:\n",
    "                    offset = str(index)\n",
    "                elif text[text_loc + 1] == token[0]:\n",
    "                    index += 1\n",
    "                    offset = str(index)\n",
    "                length = len(token)\n",
    "                index += length\n",
    "                wid =  'w' + str(counter)\n",
    "                Nafparser.create_wf(token, str(sent), offset, wid, str(length))\n",
    "                span.append(wid)\n",
    "                if token == \".\":\n",
    "                    sent += 1\n",
    "            #once all tokens are added, add markable identifying the speaker\n",
    "            #print(k, span)\n",
    "\n",
    "    Nafparser.dump(outputfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9cb0a8-4f1f-4b59-b019-d5fece1905b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_xml(xmlfile):\n",
    "\n",
    "    with open (xmlfile, \"r\") as myfile:\n",
    "        output = xmlfile.replace(\".xml\", \"-cleand.xml\")\n",
    "        with open(output, \"w\") as outfile:\n",
    "            for line in myfile:\n",
    "                if \"&nbsp;\" in line:\n",
    "                    line = line.replace(\"&nbsp;\", \"nbsp\")\n",
    "                outfile.write(line)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b92d3-9af3-41f8-b431-26ee65f9651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_xml_to_naf(xmlfile, outputfile):\n",
    "\n",
    "    cleaned_xml = clean_xml(xmlfile)\n",
    "    speaker_text_dict = extract_text(cleaned_xml)\n",
    "    if len(speaker_text_dict) > 0:\n",
    "        speaker_tokens_dict = turn_text_to_tokens(speaker_text_dict)\n",
    "        create_naf_file(speaker_text_dict, speaker_tokens_dict, outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f272fef0-10db-4b2e-895b-e537e9235df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#provide paths from the input directory to the output directory\n",
    "inputdir = '../../dbnl_input_test/'\n",
    "outputdir = '../../naf_input_test/'\n",
    "\n",
    "#check if outputdir exists, otherwise create it\n",
    "if not os.path.isdir(outputdir):\n",
    "    os.mkdir(outputdir)\n",
    "\n",
    "for filename in os.listdir(inputdir):\n",
    "    #assumes all dbnl files end with .xml, adjust if there are other endings\n",
    "    if filename.endswith(\".xml\"):\n",
    "        inputfile = os.path.join(inputdir, filename)\n",
    "        print(inputfile)\n",
    "        outputfile = os.path.join(outputdir, filename)\n",
    "        from_xml_to_naf(inputfile, outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a45e125-82b3-4dfd-b692-7191b33dfe7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
